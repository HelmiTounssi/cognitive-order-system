#!/usr/bin/env python3
"""
Point d'entrÃ©e principal du PoC - SystÃ¨me de Gestion Cognitif de Commande
Interface CLI interactive pour tester le systÃ¨me avec vrai LLM
"""

import os
import sys
from src.core.knowledge_base import KnowledgeBase
from src.rag.vector_store import VectorStore
from src.core.agent import CognitiveOrderAgent
from src.llm.llm_interface import LLMInterface


def print_banner():
    """Affiche la banniÃ¨re du PoC"""
    banner = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                              â•‘
â•‘    ğŸ§  SystÃ¨me de Gestion Cognitif de Commande               â•‘
â•‘    InfÃ©rence SÃ©mantique & Recherche Vectorielle             â•‘
â•‘                                                              â•‘
â•‘    PoC - Mind-Driven Design avec Vrai LLM                   â•‘
â•‘                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    print(banner)


def print_help():
    """Affiche l'aide et les exemples d'utilisation"""
    help_text = """
ğŸ“– GUIDE D'UTILISATION

ğŸ¯ EXEMPLES DE REQUÃŠTES :

1. CrÃ©ation de commande :
   â€¢ "CrÃ©er une nouvelle commande pour John Doe avec 3 unitÃ©s de Super Laptop et traiter le paiement"
   â€¢ "Commander 2 Gaming Mouse pour Jane Smith"
   â€¢ "Passer une commande pour Bob Johnson : 1 Mechanical Keyboard avec 2 unitÃ©s"

2. Validation de commande :
   â€¢ "Valider la commande O-12345678"
   â€¢ "Traiter la commande O-87654321"

3. Recommandations de produits :
   â€¢ "Je cherche un accessoire pour mon ordinateur portable"
   â€¢ "Quel produit recommanderiez-vous similaire Ã  Gaming Mouse ?"
   â€¢ "SuggÃ©rer des produits gaming"

4. VÃ©rification de statut :
   â€¢ "Statut de la commande O-12345678"
   â€¢ "Historique des commandes du client John Doe"

5. Autres commandes :
   â€¢ "help" - Afficher cette aide
   â€¢ "stats" - Afficher les statistiques du systÃ¨me
   â€¢ "llm_status" - VÃ©rifier le statut du LLM
   â€¢ "quit" ou "exit" - Quitter le programme

ğŸ”§ FONCTIONNALITÃ‰S DÃ‰MONTRÃ‰ES :

â€¢ InfÃ©rence sÃ©mantique sur l'ontologie RDF
â€¢ Recherche vectorielle pour la similaritÃ© de produits
â€¢ Parsing en langage naturel avec vrai LLM
â€¢ Gestion des erreurs et alternatives intelligentes
â€¢ Orchestration d'outils mÃ©tier
â€¢ Embeddings rÃ©els via API OpenAI

ğŸ’¡ CONSEILS :
â€¢ Utilisez des phrases naturelles
â€¢ SpÃ©cifiez clairement les noms de clients et produits
â€¢ Les IDs de commande sont gÃ©nÃ©rÃ©s automatiquement
â€¢ Le systÃ¨me gÃ¨re les erreurs de stock et propose des alternatives
â€¢ Le LLM amÃ©liore la comprÃ©hension et les recommandations
    """
    print(help_text)


def print_stats(knowledge_base: KnowledgeBase, vector_store: VectorStore):
    """Affiche les statistiques du systÃ¨me"""
    print("\nğŸ“Š STATISTIQUES DU SYSTÃˆME")
    print("=" * 50)
    
    # Statistiques de la base de connaissances
    try:
        clients = knowledge_base.get_instances_of_class("http://example.org/ontology/Client")
        products = knowledge_base.get_instances_of_class("http://example.org/ontology/Product")
        orders = knowledge_base.get_instances_of_class("http://example.org/ontology/Order")
        
        print(f"ğŸ‘¥ Clients: {len(clients)}")
        print(f"ğŸ“¦ Produits: {len(products)}")
        print(f"ğŸ“‹ Commandes: {len(orders)}")
        
        # Affiche quelques exemples
        if clients:
            print(f"\nğŸ‘¤ Exemples de clients:")
            for i, client_uri in enumerate(clients[:3], 1):
                client_id = client_uri.split('/')[-1]
                client_details = knowledge_base.get_client_details(client_id)
                print(f"   {i}. {client_details.get('hasName', 'N/A')} ({client_id})")
        
        if products:
            print(f"\nğŸ“¦ Exemples de produits:")
            for i, product_uri in enumerate(products[:3], 1):
                product_id = product_uri.split('/')[-1]
                product_details = knowledge_base.get_product_details(product_id)
                print(f"   {i}. {product_details.get('hasName', 'N/A')} - {product_details.get('hasPrice', 'N/A')}â‚¬ ({product_id})")
        
    except Exception as e:
        print(f"âŒ Erreur lors de la rÃ©cupÃ©ration des stats KB: {e}")
    
    # Statistiques de la base vectorielle
    try:
        vector_stats = vector_store.get_collection_stats()
        print(f"\nğŸ” Base vectorielle:")
        print(f"   Collection: {vector_stats.get('collection_name', 'N/A')}")
        print(f"   Produits indexÃ©s: {vector_stats.get('total_products', 'N/A')}")
        
    except Exception as e:
        print(f"âŒ Erreur lors de la rÃ©cupÃ©ration des stats vectorielles: {e}")
    
    print("=" * 50)


def check_llm_status(llm_interface: LLMInterface) -> bool:
    """VÃ©rifie le statut de l'interface LLM"""
    try:
        print("\nğŸ¤– STATUT DU LLM")
        print("=" * 30)
        
        if llm_interface:
            print("âœ… Interface LLM initialisÃ©e")
            print(f"   ModÃ¨le: {llm_interface.model}")
            print(f"   Embedding: {llm_interface.embedding_model}")
            
            # Test simple de l'API
            test_embedding = llm_interface.generate_embedding("test")
            if test_embedding:
                print("âœ… API OpenAI accessible")
                print(f"   Dimension embedding: {len(test_embedding)}")
                return True
            else:
                print("âŒ Erreur lors du test de l'API")
                return False
        else:
            print("âŒ Interface LLM non disponible")
            print("   Mode fallback activÃ© (logique simulÃ©e)")
            return False
            
    except Exception as e:
        print(f"âŒ Erreur lors de la vÃ©rification du LLM: {e}")
        return False


def initialize_system():
    """Initialise le systÃ¨me complet"""
    print("ğŸš€ Initialisation du systÃ¨me...")
    
    try:
        # Initialisation de la base de connaissances
        print("ğŸ“š Chargement de la base de connaissances...")
        knowledge_base = KnowledgeBase()
        print("âœ… Base de connaissances initialisÃ©e")
        
        # Initialisation de l'interface LLM
        llm_interface = None
        try:
            print("ğŸ¤– Initialisation de l'interface LLM...")
            llm_interface = LLMInterface()
            print("âœ… Interface LLM initialisÃ©e")
        except Exception as e:
            print(f"âš ï¸ Interface LLM non disponible: {e}")
            print("   Le systÃ¨me fonctionnera en mode fallback")
        
        # Initialisation de la base vectorielle
        print("ğŸ” Initialisation de la base vectorielle...")
        vector_store = VectorStore(llm_interface=llm_interface)
        print("âœ… Base vectorielle initialisÃ©e")
        
        # Initialisation de l'agent
        print("ğŸ¤– Initialisation de l'agent cognitif...")
        agent = CognitiveOrderAgent(knowledge_base, vector_store, llm_interface)
        print("âœ… Agent cognitif initialisÃ©")
        
        print("ğŸ‰ SystÃ¨me prÃªt Ã  l'utilisation!")
        return knowledge_base, vector_store, agent, llm_interface
        
    except Exception as e:
        print(f"âŒ Erreur lors de l'initialisation: {e}")
        sys.exit(1)


def main():
    """Fonction principale"""
    print_banner()
    
    # Initialisation du systÃ¨me
    knowledge_base, vector_store, agent, llm_interface = initialize_system()
    
    print("\n" + "=" * 60)
    print("ğŸ’¬ Entrez vos requÃªtes en langage naturel (ou 'help' pour l'aide)")
    print("=" * 60)
    
    # Boucle interactive
    while True:
        try:
            # Lecture de la requÃªte utilisateur
            user_input = input("\nğŸ¤” Vous: ").strip()
            
            # Commandes spÃ©ciales
            if user_input.lower() in ['quit', 'exit', 'q']:
                print("ğŸ‘‹ Au revoir!")
                break
            elif user_input.lower() == 'help':
                print_help()
                continue
            elif user_input.lower() == 'stats':
                print_stats(knowledge_base, vector_store)
                continue
            elif user_input.lower() == 'llm_status':
                check_llm_status(llm_interface)
                continue
            elif not user_input:
                continue
            
            # Traitement de la requÃªte par l'agent
            response = agent.run_agent(user_input)
            
            # Affichage de la rÃ©ponse
            print(f"\nğŸ¤– Agent: {response}")
            
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ Interruption dÃ©tectÃ©e. Au revoir!")
            break
        except EOFError:
            print("\n\nğŸ‘‹ Fin de l'entrÃ©e. Au revoir!")
            break
        except Exception as e:
            print(f"\nâŒ Erreur inattendue: {e}")
            print("ğŸ’¡ Essayez de reformuler votre requÃªte ou tapez 'help' pour l'aide")


if __name__ == "__main__":
    main() 